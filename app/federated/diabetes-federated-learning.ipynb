{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T23:13:40.311207Z",
     "iopub.status.busy": "2024-12-08T23:13:40.310692Z",
     "iopub.status.idle": "2024-12-08T23:13:59.069311Z",
     "shell.execute_reply": "2024-12-08T23:13:59.067855Z",
     "shell.execute_reply.started": "2024-12-08T23:13:40.311158Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T23:16:51.459913Z",
     "iopub.status.busy": "2024-12-08T23:16:51.459453Z",
     "iopub.status.idle": "2024-12-08T23:16:51.465698Z",
     "shell.execute_reply": "2024-12-08T23:16:51.464465Z",
     "shell.execute_reply.started": "2024-12-08T23:16:51.459859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_clients=5\n",
    "client_names = ['{}_{}'.format('client', i+1) for i in range(num_clients)]\n",
    "comms_round = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients_equ(X, y):\n",
    "    ''' return: a dictionary with keys clients' names and value as \n",
    "                data shards - tuple of data and label lists.  '''  \n",
    "\n",
    "    train_data = X.copy(deep=True)\n",
    "    train_data['has_diabetes'] = y\n",
    "    \n",
    "    pos_data = train_data[train_data['has_diabetes']==1]\n",
    "    neg_data = train_data[train_data['has_diabetes']==0]\n",
    "\n",
    "    pos_size = len(pos_data) // num_clients\n",
    "    neg_size = len(neg_data) // num_clients\n",
    "\n",
    "    pos_shards = [pos_data[i:i + pos_size] for i in range(0, pos_size * num_clients, pos_size)]\n",
    "    neg_shards = [neg_data[i:i + neg_size] for i in range(0, neg_size * num_clients, neg_size)]\n",
    "\n",
    "    return {client_names[i] : pos_shards[i].append(neg_shards[i]) for i in range(len(client_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T23:13:59.072598Z",
     "iopub.status.busy": "2024-12-08T23:13:59.071699Z",
     "iopub.status.idle": "2024-12-08T23:13:59.080444Z",
     "shell.execute_reply": "2024-12-08T23:13:59.079141Z",
     "shell.execute_reply.started": "2024-12-08T23:13:59.072538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_clients(X, y):\n",
    "    ''' return: a dictionary with keys clients' names and value as \n",
    "                data shards - tuple of data and label lists.  '''  \n",
    "    train_data = X.copy(deep=True)\n",
    "    train_data['has_diabetes'] = y\n",
    "\n",
    "    size = len(train_data)//num_clients\n",
    "    shards = [train_data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "\n",
    "    return {client_names[i] : shards[i] for i in range(len(client_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T23:13:59.082689Z",
     "iopub.status.busy": "2024-12-08T23:13:59.082197Z",
     "iopub.status.idle": "2024-12-08T23:13:59.108235Z",
     "shell.execute_reply": "2024-12-08T23:13:59.106498Z",
     "shell.execute_reply.started": "2024-12-08T23:13:59.082636Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def batch_data(data_shard, bs=32):\n",
    "    '''Takes in a clients data shard and batch size; return a Tensorflow dataset object off it'''\n",
    "    \n",
    "    #seperate shard into data and labels lists\n",
    "    data, label = data_shard.drop('has_diabetes', axis=1), data_shard['has_diabetes'] \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data.values, label.values))\n",
    "    return dataset.shuffle(len(label)).batch(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T23:13:59.111510Z",
     "iopub.status.busy": "2024-12-08T23:13:59.110557Z",
     "iopub.status.idle": "2024-12-08T23:13:59.123035Z",
     "shell.execute_reply": "2024-12-08T23:13:59.121762Z",
     "shell.execute_reply.started": "2024-12-08T23:13:59.111465Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(256,activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "loss='binary_crossentropy'\n",
    "metrics = ['accuracy']      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T23:13:59.124714Z",
     "iopub.status.busy": "2024-12-08T23:13:59.124361Z",
     "iopub.status.idle": "2024-12-08T23:13:59.139110Z",
     "shell.execute_reply": "2024-12-08T23:13:59.137900Z",
     "shell.execute_reply.started": "2024-12-08T23:13:59.124682Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    # bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    \n",
    "    global_count = sum([len(clients_trn_data[client_name]) for client_name in client_names])\n",
    "    local_count =  len(clients_trn_data[client_name])\n",
    "\n",
    "    # global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names]) *bs\n",
    "    # local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    return local_count/global_count\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T23:16:55.549428Z",
     "iopub.status.busy": "2024-12-08T23:16:55.549017Z",
     "iopub.status.idle": "2024-12-08T23:16:55.555685Z",
     "shell.execute_reply": "2024-12-08T23:16:55.554410Z",
     "shell.execute_reply.started": "2024-12-08T23:16:55.549393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    predicted = model.predict(X_test)    \n",
    "    loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('comm_round: {} | global_acc: {:.2%} | global_loss: {:.2f}'.format(comm_round, acc, loss))\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T23:13:59.161322Z",
     "iopub.status.busy": "2024-12-08T23:13:59.160789Z",
     "iopub.status.idle": "2024-12-08T23:14:00.382232Z",
     "shell.execute_reply": "2024-12-08T23:14:00.380881Z",
     "shell.execute_reply.started": "2024-12-08T23:13:59.161273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('LLCP2022_filtered.csv')\n",
    "data.drop_duplicates(inplace=True)\n",
    "data = data.astype(np.float32)\n",
    "\n",
    "data['has_diabetes'] = data['has_diabetes'].replace({2.0: 0.0})\n",
    "data['has_diabetes'] = data['has_diabetes'].astype(int)\n",
    "\n",
    "y = data['has_diabetes']\n",
    "X = data.drop('has_diabetes', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T23:14:00.465746Z",
     "iopub.status.busy": "2024-12-08T23:14:00.465382Z",
     "iopub.status.idle": "2024-12-08T23:14:00.480023Z",
     "shell.execute_reply": "2024-12-08T23:14:00.478406Z",
     "shell.execute_reply.started": "2024-12-08T23:14:00.465715Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "clients = create_clients_equ(X_train, y_train)\n",
    "clients_batched = clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T23:18:31.699852Z",
     "iopub.status.busy": "2024-12-08T23:18:31.699392Z",
     "iopub.status.idle": "2024-12-08T23:19:44.521550Z",
     "shell.execute_reply": "2024-12-08T23:19:44.520253Z",
     "shell.execute_reply.started": "2024-12-08T23:18:31.699777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "   client_1: acc = 65.15%, loss = 1.06, pred_1 = 6257/9761, pred_0 = 34116/30612  \n",
      "   client_2: acc = 29.64%, loss = 1.11, pred_1 = 34496/9761, pred_0 = 5877/30612  \n",
      "   client_3: acc = 25.88%, loss = 1.19, pred_1 = 38429/9761, pred_0 = 1944/30612  \n",
      "   client_4: acc = 75.82%, loss = 0.68, pred_1 = 1/9761, pred_0 = 40372/30612  \n",
      "   client_5: acc = 73.86%, loss = 1.12, pred_1 = 1979/9761, pred_0 = 38394/30612  \n",
      "\u001b[1m1262/1262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "comm_round: 0 | global_acc: 44.66% | global_loss: 31688456.00\n",
      "Round 2\n",
      "   client_1: acc = 48.12%, loss = 30960306.00, pred_1 = 17589/9761, pred_0 = 22784/30612  \n",
      "   client_2: acc = 48.88%, loss = 30615940.00, pred_1 = 17003/9761, pred_0 = 23370/30612  \n",
      "   client_3: acc = 48.34%, loss = 30837090.00, pred_1 = 17419/9761, pred_0 = 22954/30612  \n",
      "   client_4: acc = 52.73%, loss = 30016540.00, pred_1 = 14078/9761, pred_0 = 26295/30612  \n",
      "   client_5: acc = 49.32%, loss = 30269818.00, pred_1 = 16654/9761, pred_0 = 23719/30612  \n",
      "\u001b[1m1262/1262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "comm_round: 1 | global_acc: 49.50% | global_loss: 3057571648765952.00\n"
     ]
    }
   ],
   "source": [
    "smlp_global = create_model()\n",
    "smlp_global.build(input_shape=(None, X_train.shape[1]))\n",
    "smlp_global.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=metrics)\n",
    "\n",
    "global_model = smlp_global\n",
    "scaling_factor = 100/num_clients\n",
    "\n",
    "\n",
    "for comm_round in range(comms_round):\n",
    "    print(f\"Round {comm_round+1}\")        \n",
    "    \n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    scaled_local_weight_list = list()\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:  \n",
    "        smlp_local = create_model()\n",
    "        smlp_local.build(input_shape=(None, X_train.shape[1]))\n",
    "        local_model = smlp_local\n",
    "        local_model.compile(loss=loss,  \n",
    "                      optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        \n",
    "        local_model.set_weights(global_weights)\n",
    "\n",
    "        # y_client = np.concatenate([labels.numpy() for _, labels in clients_batched[client]])\n",
    "        x_client = clients_batched[client].drop('has_diabetes', axis=1)\n",
    "        y_client = clients_batched[client]['has_diabetes']\n",
    "\n",
    "        class_weights = compute_class_weight( class_weight='balanced', classes=np.unique(y_client), y=y_client)\n",
    "        class_weights_dict = dict(enumerate(class_weights)) \n",
    "    \n",
    "        local_model.fit(x=x_client.to_numpy(),y=y_client.to_numpy(), epochs=2, verbose=0,class_weight=class_weights_dict)\n",
    "        \n",
    "        local_loss, local_accuracy = local_model.evaluate(X_test, y_test, verbose=0)\n",
    "        predicted = local_model.predict(X_test,verbose=0) \n",
    "  \n",
    "        print(f\"   {client}: acc = {local_accuracy:.2%}, loss = {local_loss:.2f}, pred_1 = {np.sum(predicted>=0.5)}/{np.count_nonzero(y_test==1)}, pred_0 = {np.sum(predicted<0.5)}/{np.count_nonzero(y_test==0)}  \")\n",
    "    \n",
    "        #scale the model weights and add to list\n",
    "        # scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "\n",
    "\n",
    "    K.clear_session()\n",
    "    \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "\n",
    "    global_model.set_weights(average_weights)\n",
    "    test_model(X_test, y_test, global_model,comm_round)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6199743,
     "sourceId": 10060577,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
